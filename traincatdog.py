# -*- coding: utf-8 -*-
"""trainCatDog.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hrPhtiPxUt0IcPI1YPEdxZU49aZzG-fP
"""

from __future__ import absolute_import, division, print_function, unicode_literals
import numpy as np
import matplotlib.pyplot as plt
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam
from keras.utils.np_utils import to_categorical
import random

from keras.layers import Dropout
from keras.layers import Flatten
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D

import os, cv2, itertools
from sklearn.model_selection import train_test_split
from sklearn.externals import joblib
from sklearn.utils import shuffle
import pickle as pk
from google.colab import drive

os.getcwd()

drive.mount('/content/drive')

os.environ['KAGGLE_CONFIG_DIR'] = "/content/drive/My Drive/Kaggle"

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My Drive/Kaggle

# download and unzip data train 
#!kaggle competitions download -c dogs-vs-cats
#!unzip \*.zip

TRAIN_DIR = 'train/'

ROWS = 64
COLS = 64
CHANNELS = 3

def VGG16_model():
    model = Sequential()
    
    model.add(Conv2D(64, (3, 3), input_shape = (64,64,3), activation = 'relu'))
    model.add(Conv2D(64, (3, 3), activation = 'relu'))
    model.add(MaxPooling2D(pool_size = (2, 2)))
    model.add(Dropout(0.25))

    model.add(Conv2D(128, (3, 3), activation = 'relu'))
    model.add(Conv2D(128, (3, 3), activation = 'relu'))
    model.add(MaxPooling2D(pool_size = (2, 2)))
    model.add(Dropout(0.25))
    
    model.add(Conv2D(256, (3, 3), activation = 'relu'))
    model.add(Conv2D(256, (3, 3), activation = 'relu'))
    model.add(MaxPooling2D(pool_size = (2, 2)))
    model.add(Dropout(0.4))
    
    model.add(Conv2D(512, (1, 1), activation = 'relu'))
    model.add(MaxPooling2D(pool_size = (2, 2)))
    
    model.add(Flatten())
    model.add(Dense(units = 128, activation = 'relu'))
    model.add(Dropout(0.5))
    model.add(Dense(units = 2, activation = 'softmax'))
    
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

model11 = VGG16_model()
print(model11.summary())

print(os.listdir('.'))

train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)]

print(train_images)

def read_image(file_path):
  img = cv2.imread(file_path, cv2.IMREAD_COLOR)
  return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)

def prep_data(images):
  m = len(images)
  n_x = ROWS*COLS*CHANNELS
  
  X = np.ndarray((m,ROWS,COLS,CHANNELS), dtype=np.uint8)
  y = np.zeros((m,1))
  print("X.shape is {}".format(X.shape))
  
  for i,image_file in enumerate(images) :
    image = read_image(image_file)
    X[i,:] = np.squeeze(image.reshape((ROWS, COLS, CHANNELS)))
    if 'dog' in image_file.lower() :
      y[i,0] = 1
    elif 'cat' in image_file.lower() :
      y[i,0] = 0
    else : # for test data
      y[i,0] = image_file.split('/')[-1].split('.')[0]
      
    if i%100 == 0 :
      percent = (i/m) *100
      if i == m:
        print("Process done")
      else :
        print("Proceed {} of {} - {}%".format(i, m,percent))
  return X,y

X_train, y_train = prep_data(train_images)

print(X_train.shape)

X, y = shuffle(X_train, y_train)

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1)

print("Train shape: {}".format(X_train.shape))
print("Train label shape: {}".format(y_train.shape))
print("Validation shape: {}".format(X_val.shape))
print("Validation label shape: {}".format(y_val.shape))

X_train_norm = X_train / 255
X_val_norm = X_val / 255

y_train_one_hot = to_categorical(y_train)
print(y_train_one_hot.shape)

num_classes = y_train_one_hot.shape[1]
print(num_classes)

y_val_one_hot = to_categorical(y_val)
print(y_val_one_hot.shape)

history = model11.fit(X_train_norm, y_train_one_hot, validation_data=(X_val_norm, y_val_one_hot), epochs=30, batch_size = 500)

_, ax = plt.subplots(1, 2)

ax[0].plot(history.history['accuracy'])
plt.xlabel('epoch')
ax[0].legend(['accuracy'])

ax[1].plot(history.history['loss'])
plt.title('loss')
plt.ylabel('epoch')
ax[1].legend(['loss'])

from keras.models import load_model

model11.save('my_model.h5')

a =X_val[0].reshape(1,64,64,3)

a.shape

y_pred = model11.predict_classes(X_val)

y_pred

y_train

y_val

y_val.shape

y_pred.reshape(5000,1)

from keras import backend as K

def sensitivity(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    return true_positives / (possible_positives + K.epsilon())

def specificity(y_true, y_pred):
    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))
    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))
    return true_negatives / (possible_negatives + K.epsilon())

b = sensitivity(y_val, y_pred)

print(b)

neg_y_true = 1 - y_val

print(neg_y_true)

true_cats = 0
true_dogs = 0
false_dogs = 0
false_cats = 0
for i in range(y_pred.shape[0]):
  if(y_val[i][0] == y_pred[i]  and y_val[i][0] == 0):
    true_cats += 1
  elif(y_val[i][0] == y_pred[i] and y_val[i][0] == 1):
    true_dogs += 1
  elif(y_val[i][0] == 0):
    false_dogs += 1
  else: false_cats += 1

false_dogs

def sensitivity(TP, TN, FP, FN):
    return (TP)/(TP+FN)
def specificity(TP, TN, FP, FN):
    return (TN)/(TN+FP)
def F1_Score(TP, TN, FP, FN):
    return (2*TP)/(2*TP+FP+FN)

sensitivity = sensitivity(true_dogs, true_cats, false_dogs, false_cats)
specificity = specificity(true_dogs, true_cats, false_dogs, false_cats)
f_measures = F1_Score(true_dogs, true_cats, false_dogs, false_cats)

print('The classification sensitivity is %f'%sensitivity)
print('The classification specificity is %f'%specificity)
print('The classification F1_Score is %f'%f_measures)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_val, y_pred)
def plot_confusion_matrix(y_true, y_pred, classes,
                          normalize=False,
                          title=None,
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if not title:
        if normalize:
            title = 'Normalized confusion matrix'
        else:
            title = 'Confusion matrix, without normalization'

    # Compute confusion matrix
    cm = confusion_matrix(y_true, y_pred)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    fig, ax = plt.subplots()
    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)
    ax.figure.colorbar(im, ax=ax)
    # We want to show all ticks...
    ax.set(xticks=np.arange(cm.shape[1]),
           yticks=np.arange(cm.shape[0]),
           # ... and label them with the respective list entries
           xticklabels=classes, yticklabels=classes,
           title=title,
           ylabel='True label',
           xlabel='Predicted label')

    # Rotate the tick labels and set their alignment.
    plt.setp(ax.get_xticklabels(), ha="center",
             rotation_mode="anchor")

    # Loop over data dimensions and create text annotations.
    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, format(cm[i, j], fmt),
                    ha="center", va="center",
                    color="white" if cm[i, j] > thresh else "black")
    fig.tight_layout()
    return ax

class_names = [0,1]
plot_confusion_matrix(y_val, y_pred, classes=class_names,
                      title='Confusion matrix, without normalization')

